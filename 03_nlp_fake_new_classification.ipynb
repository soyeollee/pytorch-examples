{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import sample\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEVICE = 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                                              title  \\\n0           8476                       You Can Smell Hillary’s Fear   \n1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2           3608        Kerry to go to Paris in gesture of sympathy   \n3          10142  Bernie supporters on Twitter erupt in anger ag...   \n4            875   The Battle of New York: Why This Primary Matters   \n...          ...                                                ...   \n6330        4490  State Department says it can't find emails fro...   \n6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n\n                                                   text label  \n0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n4     It's primary day in New York and front-runners...  REAL  \n...                                                 ...   ...  \n6330  The State Department told the Republican Natio...  REAL  \n6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n\n[6335 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary’s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6330</th>\n      <td>4490</td>\n      <td>State Department says it can't find emails fro...</td>\n      <td>The State Department told the Republican Natio...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>6331</th>\n      <td>8062</td>\n      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>6332</th>\n      <td>8622</td>\n      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>6333</th>\n      <td>4021</td>\n      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>6334</th>\n      <td>4330</td>\n      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n      <td>REAL</td>\n    </tr>\n  </tbody>\n</table>\n<p>6335 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"data/news.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              title  \\\n0        8476                       You Can Smell Hillary’s Fear   \n1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2        3608        Kerry to go to Paris in gesture of sympathy   \n3       10142  Bernie supporters on Twitter erupt in anger ag...   \n4         875   The Battle of New York: Why This Primary Matters   \n\n                                                text label  \\\n0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n4  It's primary day in New York and front-runners...  REAL   \n\n                                           titletext  \n0  You Can Smell Hillary’s Fear Daniel Greenfield...  \n1  Watch The Exact Moment Paul Ryan Committed Pol...  \n2  Kerry to go to Paris in gesture of sympathy U....  \n3  Bernie supporters on Twitter erupt in anger ag...  \n4  The Battle of New York: Why This Primary Matte...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n      <th>titletext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary’s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n      <td>The Battle of New York: Why This Primary Matte...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['titletext'] = df['title'] + \" \" + df['text']\n",
    "# Cap the sentences length\n",
    "df['titletext'] = df['titletext'].str.slice(start=0, stop=1000)  # 최대 1000개 까지만\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "UNK_TOKEN = 9  # 미등록 어휘\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2id = {\"__unk__\": UNK_TOKEN}\n",
    "        self.id2word = {UNK_TOKEN: \"__unk__\"}\n",
    "        self.n_words = 1\n",
    "\n",
    "        self.tag2id = {\"FAKE\": 0, \"REAL\": 1}\n",
    "        self.id2tag = {0: \"FAKE\", 1: \"REAL\"}\n",
    "\n",
    "    def index_words(self, words):\n",
    "        word_indexes = [self.index_word(w) for w in words]\n",
    "        return word_indexes\n",
    "\n",
    "    def index_tags(self, tag):\n",
    "        tag_index = self.tag2id[tag]\n",
    "        return tag_index\n",
    "\n",
    "    def index_word(self, w):\n",
    "        if w not in self.word2id:\n",
    "            self.word2id[w] = self.n_words\n",
    "            self.id2word[self.n_words] = w\n",
    "            self.n_words += 1\n",
    "        return self.word2id[w]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "vocab = Vocab()\n",
    "def prepare_data(data, vocab, input_field):\n",
    "    data_sequences = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        words = row[input_field].split()\n",
    "        tags = row[\"label\"]\n",
    "        word_ids = torch.tensor(vocab.index_words(words), dtype=torch.long).to(DEVICE)\n",
    "        tag_ids = torch.tensor(vocab.index_tags(tags), dtype=torch.long).to(DEVICE)\n",
    "        data_sequences.append([word_ids, tag_ids])\n",
    "\n",
    "    return data_sequences, vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Create data sequnce\n",
    "\n",
    "sequences, vocab = prepare_data(df, vocab, \"titletext\")\n",
    "x = [i[0] for i in sequences]\n",
    "y = [i[1] for i in sequences]\n",
    "\n",
    "# pad sentences to use batches\n",
    "padded_x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "x = [i for i in padded_x]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84569\n"
     ]
    }
   ],
   "source": [
    "# Number of unique words\n",
    "\n",
    "print(vocab.n_words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Split data to train, validation and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "test_sequences = list(zip(x_test,y_test))\n",
    "test_sequences = [list(x) for x in test_sequences]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "train_sequences = list(zip(x_train,y_train))\n",
    "train_sequences = [list(x) for x in train_sequences]\n",
    "val_sequences = list(zip(x_val,y_val))\n",
    "val_sequences = [list(x) for x in val_sequences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, bidirectional, dropout):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        directions = 2 if self.bidirectional else 1\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, bidirectional=self.bidirectional, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*directions, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        num_dimensions = len(input_sentence)\n",
    "        sentence = input_sentence.clone().detach().to(DEVICE)\n",
    "        embedded = self.embedding(sentence)\n",
    "        packed_output, (hidden, cell) = self.lstm(embedded.view(num_dimensions, sentence.size()[1], self.embedding_size))\n",
    "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        output = self.dropout(self.fc1(hidden))\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Dataset\n",
    "title_sequences, vocab = prepare_data(df, vocab, \"title\")\n",
    "title_x = [i[0] for i in title_sequences]\n",
    "title_y = [i[1] for i in title_sequences]\n",
    "\n",
    "# pad sentences to use batches\n",
    "title_padded_x = torch.nn.utils.rnn.pad_sequence(title_x, batch_first=True)\n",
    "title_x = [i for i in title_padded_x]\n",
    "\n",
    "title_x_train, title_x_test, title_y_train, title_y_test = train_test_split(title_x, title_y, test_size=0.2, random_state=42)\n",
    "\n",
    "title_test_sequences = list(zip(title_x_test,title_y_test))\n",
    "title_test_sequences = [list(x) for x in title_test_sequences]\n",
    "title_train_sequences = list(zip(title_x_train,title_y_train))\n",
    "title_train_sequences = [list(x) for x in title_train_sequences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNet(\n",
      "  (embedding): Embedding(84569, 32)\n",
      "  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMNet(input_size=vocab.n_words, embedding_size=32, hidden_size=64, output_size=len(vocab.id2tag), n_layers=2, bidirectional=False, dropout=0.2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "train_loader = DataLoader(title_train_sequences, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(title_test_sequences, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def evaluate(eval_sequences, batch_size):\n",
    "    eval_loader = DataLoader(eval_sequences, batch_size=batch_size, shuffle=True)\n",
    "    preds = []\n",
    "    tags = []\n",
    "    with torch.no_grad():\n",
    "        for words, tag in eval_loader:\n",
    "            preds.append(model(words).argmax(dim=1).cpu().data.numpy())\n",
    "            tags.append(tag.cpu().data.numpy())\n",
    "    preds = np.concatenate(preds).ravel()\n",
    "    tags = np.concatenate(tags).ravel()\n",
    "    accuracy = (preds == tags).sum() / len(tags) * 100\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Batch: 0,  Loss: 0.0043284655548632145\n",
      "Epoch 0, Training Accuracy: 50.493291239147595%\n",
      "Epoch 0, Validation Accuracy: 51.065509076558804%\n",
      "Epoch #1, Batch: 0,  Loss: 0.004187161568552256\n",
      "Epoch 1, Training Accuracy: 60.93133385951065%\n",
      "Epoch 1, Validation Accuracy: 60.37884767166535%\n",
      "Epoch #2, Batch: 0,  Loss: 0.004216537810862064\n",
      "Epoch 2, Training Accuracy: 64.75927387529597%\n",
      "Epoch 2, Validation Accuracy: 63.378058405682715%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m words, tags \u001B[38;5;129;01min\u001B[39;00m  \u001B[38;5;28miter\u001B[39m(train_loader):\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     seq_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(words)\n\u001B[1;32m      8\u001B[0m     sentence_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/venvs/tct2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1786\u001B[0m, in \u001B[0;36mModule.zero_grad\u001B[0;34m(self, set_to_none)\u001B[0m\n\u001B[1;32m   1784\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1785\u001B[0m     p\u001B[38;5;241m.\u001B[39mgrad\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1786\u001B[0m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    count = 0\n",
    "    epoch_loss = 0.\n",
    "    model.train()\n",
    "    for words, tags in  iter(train_loader):\n",
    "        model.zero_grad()\n",
    "        seq_len = len(words)\n",
    "        sentence_loss = 0\n",
    "        output = model(words)\n",
    "        sentence_loss = criterion(output, tags)\n",
    "        sentence_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += sentence_loss.item()\n",
    "\n",
    "    print(f\"Epoch #{e}, Batch: {count},  Loss: {sentence_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "    train_accuracy = evaluate(title_train_sequences, BATCH_SIZE)\n",
    "    print(f\"Epoch {e}, Training Accuracy: {train_accuracy}%\")\n",
    "\n",
    "    test_accuracy = evaluate(title_test_sequences, BATCH_SIZE)\n",
    "    print(f\"Epoch {e}, Validation Accuracy: {test_accuracy}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
