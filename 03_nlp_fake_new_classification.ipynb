{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import sample\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEVICE = 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                                              title  \\\n0           8476                       You Can Smell Hillary’s Fear   \n1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2           3608        Kerry to go to Paris in gesture of sympathy   \n3          10142  Bernie supporters on Twitter erupt in anger ag...   \n4            875   The Battle of New York: Why This Primary Matters   \n...          ...                                                ...   \n6330        4490  State Department says it can't find emails fro...   \n6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n\n                                                   text label  \n0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n4     It's primary day in New York and front-runners...  REAL  \n...                                                 ...   ...  \n6330  The State Department told the Republican Natio...  REAL  \n6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n\n[6335 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary’s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6330</th>\n      <td>4490</td>\n      <td>State Department says it can't find emails fro...</td>\n      <td>The State Department told the Republican Natio...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>6331</th>\n      <td>8062</td>\n      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>6332</th>\n      <td>8622</td>\n      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>6333</th>\n      <td>4021</td>\n      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>6334</th>\n      <td>4330</td>\n      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n      <td>REAL</td>\n    </tr>\n  </tbody>\n</table>\n<p>6335 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"data/news.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              title  \\\n0        8476                       You Can Smell Hillary’s Fear   \n1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2        3608        Kerry to go to Paris in gesture of sympathy   \n3       10142  Bernie supporters on Twitter erupt in anger ag...   \n4         875   The Battle of New York: Why This Primary Matters   \n\n                                                text label  \\\n0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n4  It's primary day in New York and front-runners...  REAL   \n\n                                           titletext  \n0  You Can Smell Hillary’s Fear Daniel Greenfield...  \n1  Watch The Exact Moment Paul Ryan Committed Pol...  \n2  Kerry to go to Paris in gesture of sympathy U....  \n3  Bernie supporters on Twitter erupt in anger ag...  \n4  The Battle of New York: Why This Primary Matte...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n      <th>titletext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary’s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n      <td>The Battle of New York: Why This Primary Matte...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['titletext'] = df['title'] + \" \" + df['text']\n",
    "# Cap the sentences length\n",
    "df['titletext'] = df['titletext'].str.slice(start=0, stop=1000)  # 최대 1000개 까지만\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "UNK_TOKEN = 9  # 미등록 어휘\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2id = {\"__unk__\": UNK_TOKEN}\n",
    "        self.id2word = {UNK_TOKEN: \"__unk__\"}\n",
    "        self.n_words = 1\n",
    "\n",
    "        self.tag2id = {\"FAKE\": 0, \"REAL\": 1}\n",
    "        self.id2tag = {0: \"FAKE\", 1: \"REAL\"}\n",
    "\n",
    "    def index_words(self, words):\n",
    "        word_indexes = [self.index_word(w) for w in words]\n",
    "        return word_indexes\n",
    "\n",
    "    def index_tags(self, tag):\n",
    "        tag_index = self.tag2id[tag]\n",
    "        return tag_index\n",
    "\n",
    "    def index_word(self, w):\n",
    "        if w not in self.word2id:\n",
    "            self.word2id[w] = self.n_words\n",
    "            self.id2word[self.n_words] = w\n",
    "            self.n_words += 1\n",
    "        return self.word2id[w]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "vocab = Vocab()\n",
    "def prepare_data(data, vocab, input_field):\n",
    "    data_sequences = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        words = row[input_field].split()\n",
    "        tags = row[\"label\"]\n",
    "        word_ids = torch.tensor(vocab.index_words(words), dtype=torch.long).to(DEVICE)\n",
    "        tag_ids = torch.tensor(vocab.index_tags(tags), dtype=torch.long).to(DEVICE)\n",
    "        data_sequences.append([word_ids, tag_ids])\n",
    "\n",
    "    return data_sequences, vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Create data sequnce\n",
    "\n",
    "sequences, vocab = prepare_data(df, vocab, \"titletext\")\n",
    "x = [i[0] for i in sequences]\n",
    "y = [i[1] for i in sequences]\n",
    "\n",
    "# pad sentences to use batches\n",
    "padded_x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "x = [i for i in padded_x]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84569\n"
     ]
    }
   ],
   "source": [
    "# Number of unique words\n",
    "\n",
    "print(vocab.n_words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Split data to train, validation and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "test_sequences = list(zip(x_test,y_test))\n",
    "test_sequences = [list(x) for x in test_sequences]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "train_sequences = list(zip(x_train,y_train))\n",
    "train_sequences = [list(x) for x in train_sequences]\n",
    "val_sequences = list(zip(x_val,y_val))\n",
    "val_sequences = [list(x) for x in val_sequences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, bidirectional, dropout):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        directions = 2 if self.bidirectional else 1\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, bidirectional=self.bidirectional, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*directions, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        num_dimensions = len(input_sentence)\n",
    "        sentence = input_sentence.clone().detach().to(DEVICE)\n",
    "        embedded = self.embedding(sentence)\n",
    "        packed_output, (hidden, cell) = self.lstm(embedded.view(num_dimensions, sentence.size()[1], self.embedding_size))\n",
    "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        output = self.dropout(self.fc1(hidden))\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "class RNNNet(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, bidirectional, dropout):\n",
    "        super(RNNNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.directions = 2 if self.bidirectional else 1\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, n_layers, dropout=dropout, batch_first=True, bidirectional=self.bidirectional)\n",
    "        # self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, bidirectional=self.bidirectional, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*self.directions, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        sentence = input_sentence.clone().detach().to(DEVICE)\n",
    "        embedded = self.embedding(sentence)  # shape=[batch, num_words, embedding_size]\n",
    "\n",
    "        # print(embedded.shape)\n",
    "        output, hidden = self.rnn(embedded) # output shape = [batch, 53(padding size), hidden_size]\n",
    "\n",
    "        # output shape = torch.Size([32, 53, 64])\n",
    "        output = self.fc1(output[:, -1])  # output[:, -1] -> 문장의 마지막 단어\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "# Dataset\n",
    "title_sequences, vocab = prepare_data(df, vocab, \"title\")\n",
    "title_x = [i[0] for i in title_sequences]\n",
    "title_y = [i[1] for i in title_sequences]\n",
    "\n",
    "# pad sentences to use batches\n",
    "title_padded_x = torch.nn.utils.rnn.pad_sequence(title_x, batch_first=True)\n",
    "title_x = [i for i in title_padded_x]\n",
    "\n",
    "title_x_train, title_x_test, title_y_train, title_y_test = train_test_split(title_x, title_y, test_size=0.2, random_state=42)\n",
    "\n",
    "title_test_sequences = list(zip(title_x_test,title_y_test))\n",
    "title_test_sequences = [list(x) for x in title_test_sequences]\n",
    "title_train_sequences = list(zip(title_x_train,title_y_train))\n",
    "title_train_sequences = [list(x) for x in title_train_sequences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNet(\n",
      "  (embedding): Embedding(84569, 32)\n",
      "  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMNet(input_size=vocab.n_words, embedding_size=32, hidden_size=64, output_size=len(vocab.id2tag), n_layers=2, bidirectional=True, dropout=0.2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "train_loader = DataLoader(title_train_sequences, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(title_test_sequences, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "def evaluate(eval_sequences, batch_size):\n",
    "    eval_loader = DataLoader(eval_sequences, batch_size=batch_size, shuffle=True)\n",
    "    preds = []\n",
    "    tags = []\n",
    "    with torch.no_grad():\n",
    "        for words, tag in eval_loader:\n",
    "            preds.append(model(words).argmax(dim=1).cpu().data.numpy())\n",
    "            tags.append(tag.cpu().data.numpy())\n",
    "    preds = np.concatenate(preds).ravel()\n",
    "    tags = np.concatenate(tags).ravel()\n",
    "    accuracy = (preds == tags).sum() / len(tags) * 100\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[235], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m seq_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(words)\n\u001B[1;32m      8\u001B[0m sentence_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 9\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m sentence_loss \u001B[38;5;241m=\u001B[39m criterion(output, tags)\n\u001B[1;32m     11\u001B[0m sentence_loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/venvs/tct2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[190], line 22\u001B[0m, in \u001B[0;36mLSTMNet.forward\u001B[0;34m(self, input_sentence)\u001B[0m\n\u001B[1;32m     20\u001B[0m sentence \u001B[38;5;241m=\u001B[39m input_sentence\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[1;32m     21\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(sentence)\n\u001B[0;32m---> 22\u001B[0m packed_output, (hidden, cell) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedded\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_dimensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msentence\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m hidden \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((hidden[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m, :, :], hidden[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :, :]), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     24\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(hidden))\n",
      "File \u001B[0;32m~/venvs/tct2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/venvs/tct2023/lib/python3.9/site-packages/torch/nn/modules/rnn.py:691\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 691\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    694\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m    695\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    count = 0\n",
    "    epoch_loss = 0.\n",
    "    model.train()\n",
    "    for words, tags in  iter(train_loader):\n",
    "        model.zero_grad()\n",
    "        seq_len = len(words)\n",
    "        sentence_loss = 0\n",
    "        output = model(words)\n",
    "        sentence_loss = criterion(output, tags)\n",
    "        sentence_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += sentence_loss.item()\n",
    "\n",
    "    print(f\"Epoch #{e}, Batch: {count},  Loss: {sentence_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "    train_accuracy = evaluate(title_train_sequences, BATCH_SIZE)\n",
    "    print(f\"Epoch {e}, Training Accuracy: {train_accuracy}%\")\n",
    "\n",
    "    test_accuracy = evaluate(title_test_sequences, BATCH_SIZE)\n",
    "    print(f\"Epoch {e}, Validation Accuracy: {test_accuracy}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
