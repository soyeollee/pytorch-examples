{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Transfer Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchsummary import summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "model = torchvision.models.mobilenet_v2(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 166.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224), device='cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def summary_with_freeze(model, input_size, batch_size=-1, device=\"cuda\", num_freeze=30):\n",
    "\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            if module_idx < num_freeze:\n",
    "                try:\n",
    "                    module.weight.requires_grad = False\n",
    "                    module.bias.requires_grad = False\n",
    "                except:  # not have grad\n",
    "                    pass\n",
    "\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "\n",
    "            try:\n",
    "                if module.weight.requires_grad == True:\n",
    "                    summary[m_key]['grad'] = 1\n",
    "                else:\n",
    "                    summary[m_key]['grad'] = 0\n",
    "            except:\n",
    "                summary[m_key]['grad'] = -1\n",
    "\n",
    "\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "            and not (module == model)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    device = device.lower()\n",
    "    assert device in [\n",
    "        \"cuda\",\n",
    "        \"cpu\",\n",
    "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "\n",
    "    if device == \"cuda\" and torch.cuda.is_available():\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "    # print(type(x[0]))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    line_new = \"{:>20}  {:>25} {:>15} {:>7}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\", \"Grad\")\n",
    "    print(line_new)\n",
    "    print(\"========================================================================\")\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        # line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "        #     layer,\n",
    "        #     str(summary[layer][\"output_shape\"]),\n",
    "        #     \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        # )\n",
    "        line_new = \"{:>20}  {:>25} {:>15} {:>7}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "            summary[layer]['grad']\n",
    "        )\n",
    "\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        print(line_new)\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n",
    "    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    print(\"========================================================================\")\n",
    "    print(\"Total params: {0:,}\".format(total_params))\n",
    "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
    "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Input size (MB): %0.2f\" % total_input_size)\n",
    "    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
    "    print(\"Params size (MB): %0.2f\" % total_params_size)\n",
    "    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
    "    print(\"------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #    Grad\n",
      "========================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864       0\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64       0\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0      -1\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288       0\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64       0\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0      -1\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512       0\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32       0\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0      -1\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536       0\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192       0\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0      -1\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864       0\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192       0\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0      -1\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304       0\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48       0\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0      -1\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456       0\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288       0\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0      -1\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296       0\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288       0\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0      -1\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456       0\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48       0\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0      -1\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456       0\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288       0\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0      -1\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296       1\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288       1\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0      -1\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608       1\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64       1\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0      -1\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144       1\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384       1\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0      -1\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728       1\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384       1\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0      -1\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144       1\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64       1\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0      -1\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144       1\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384       1\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0      -1\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728       1\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384       1\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0      -1\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144       1\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64       1\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0      -1\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144       1\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384       1\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0      -1\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728       1\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384       1\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0      -1\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288       1\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128       1\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0      -1\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576       1\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456       1\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576       1\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128       1\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0      -1\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576       1\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456       1\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576       1\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128       1\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0      -1\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576       1\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456       1\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576       1\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128       1\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0      -1\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576       1\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456       1\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768       1\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0      -1\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864       1\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192       1\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0      -1\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296       1\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152       1\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0      -1\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184       1\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152       1\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0      -1\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296       1\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192       1\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0      -1\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296       1\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152       1\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0      -1\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184       1\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152       1\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0      -1\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296       1\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192       1\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0      -1\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296       1\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152       1\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0      -1\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184       1\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152       1\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0      -1\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160       1\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320       1\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0      -1\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600       1\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920       1\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0      -1\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640       1\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920       1\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0      -1\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600       1\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320       1\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0      -1\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600       1\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920       1\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0      -1\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640       1\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920       1\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0      -1\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600       1\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320       1\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0      -1\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600       1\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920       1\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0      -1\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640       1\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920       1\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0      -1\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200       1\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640       1\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0      -1\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600       1\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560       1\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0      -1\n",
      "         Dropout-157                 [-1, 1280]               0      -1\n",
      "          Linear-158                 [-1, 1000]       1,281,000       1\n",
      "========================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,485,336\n",
      "Non-trainable params: 19,536\n",
      "------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 166.81\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary_with_freeze(model, (3, 224, 224), device='cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
